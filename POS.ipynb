{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9416962-2f82-4832-80dd-cca91f6b3e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hazm in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (0.9.3)\n",
      "Requirement already satisfied: fasttext-wheel<0.10.0,>=0.9.2 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from hazm) (0.9.2)\n",
      "Requirement already satisfied: gensim<5.0.0,>=4.3.1 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from hazm) (4.3.3)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from hazm) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.24.3 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from hazm) (1.26.4)\n",
      "Requirement already satisfied: python-crfsuite<0.10.0,>=0.9.9 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from hazm) (0.9.11)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=1.2.2 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from hazm) (1.7.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (3.0.1)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from fasttext-wheel<0.10.0,>=0.9.2->hazm) (80.9.0)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from gensim<5.0.0,>=4.3.1->hazm) (7.3.1)\n",
      "Requirement already satisfied: click in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (8.3.0)\n",
      "Requirement already satisfied: joblib in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from nltk<4.0.0,>=3.8.1->hazm) (4.67.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from scikit-learn<2.0.0,>=1.2.2->hazm) (3.6.0)\n",
      "Requirement already satisfied: wrapt in /home/arefe/Downloads/NLP/.venv/lib/python3.12/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.1->hazm) (1.17.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b1134b8-1e21-4863-9a21-7f0f552d712b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19ef43e8-16c4-4315-8a74-c68c90b297f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ما', 'PRO'), ('بسیار', 'ADV'), ('کتاب', 'N'), ('می\\u200cخوانیم', 'V')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = POSTagger(model='pos_tagger.model')\n",
    "tagger.tag(word_tokenize('ما بسیار کتاب می‌خوانیم'))\n",
    "[('ما', 'PRO'), ('بسیار', 'ADV'), ('کتاب', 'N'), ('می‌خوانیم', 'V')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9b7f0d2-8940-4e9d-ae35-75fbf4d782cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved -> data/pairs_pos_sample.csv\n",
      "                                             persian  \\\n",
      "0  رئیس‌جمهور تاکید کرد: کار این دولت فقط با نتیج...   \n",
      "1                          من دیگر تو را دوست ندارم.   \n",
      "2                   ما یک خانه کامل در بلوک b داریم.   \n",
      "3  عکس‌های خود را به pr@cuibul. com بفرستید یا در...   \n",
      "4                 نه. این فقط شما را عالی‌تر می‌کند.   \n",
      "5                      1396 / 12 / 9 12: 05: 56 ق. ظ   \n",
      "6                                      (39 کیلوبایت)   \n",
      "7               Herscher (Illinois) 815426 **** تلفن   \n",
      "8  همه‌ی چیزایی که «چندلر» از روی. احساس گناه گرف...   \n",
      "9                  11. موتور تون جایزه بزرگ (مسابقه)   \n",
      "\n",
      "                                         persian_pos  \n",
      "0  رئیس‌جمهور/NOUN تاکید/NOUN کرد/VERB :/PUNCT کا...  \n",
      "1  من/PRON دیگر/ADV تو/PRON را/ADP دوست/NOUN ندار...  \n",
      "2  ما/PRON یک/NUM خانه/NOUN,EZ کامل/ADJ در/ADP بل...  \n",
      "3  عکس‌های/NOUN,EZ خود/PRON را/ADP به/ADP pr@cuib...  \n",
      "4  نه/ADV ./PUNCT این/PRON فقط/ADV شما/PRON را/AD...  \n",
      "5  ۱۳۹۶/NUM //PUNCT ۱۲/NUM //PUNCT ۹/NUM ۱۲:/NUM,...  \n",
      "6               (/PUNCT ۳۹/NUM کیلوبایت/NOUN )/PUNCT  \n",
      "7  Herscher/NOUN (/PUNCT Illinois/NOUN )/PUNCT ۸۱...  \n",
      "8  همه‌ی/DET,EZ چیزایی/NOUN که/SCONJ «/PUNCT چندل...  \n",
      "9  ۱۱./NOUN موتور/NOUN,EZ تون/NOUN جایزه/NOUN,EZ ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from hazm import Normalizer, word_tokenize, POSTagger\n",
    "\n",
    "# edit paths as needed\n",
    "IN_CSV  = \"data/test.csv\"\n",
    "OUT_CSV = \"data/pairs_pos_sample.csv\"\n",
    "MODEL   = \"pos_tagger.model\"           # e.g. \"resources/postagger.model\"\n",
    "DELIM   = \",\"                          # change if your CSV uses another delimiter\n",
    "\n",
    "# read only first 10 rows\n",
    "df = pd.read_csv(IN_CSV, delimiter=DELIM, nrows=10)\n",
    "\n",
    "tagger = POSTagger(model=MODEL)\n",
    "norm = Normalizer(persian_numbers=True)\n",
    "\n",
    "def pos_tag_line(text: str) -> str:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    tokens = word_tokenize(norm.normalize(text))\n",
    "    return \" \".join(f\"{tok}/{pos}\" for tok, pos in tagger.tag(tokens))\n",
    "\n",
    "df[\"persian_pos\"] = df[\"persian\"].apply(pos_tag_line)\n",
    "\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(\"Saved ->\", OUT_CSV)\n",
    "# print(df[[\"persian\", \"persian_pos\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a98cb8dd-62b8-4c9f-b672-d109e9608e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5075f_row0_col1, #T_5075f_row1_col1, #T_5075f_row2_col1, #T_5075f_row3_col1, #T_5075f_row4_col1, #T_5075f_row5_col1, #T_5075f_row6_col1, #T_5075f_row7_col1, #T_5075f_row8_col1, #T_5075f_row9_col1 {\n",
       "  white-space: pre;\n",
       "  font-family: monospace;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5075f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5075f_level0_col0\" class=\"col_heading level0 col0\" >persian</th>\n",
       "      <th id=\"T_5075f_level0_col1\" class=\"col_heading level0 col1\" >pos_pretty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5075f_row0_col0\" class=\"data row0 col0\" >رئیس‌جمهور تاکید کرد: کار این دولت فقط با نتیجه ارزیابی می‌شود.</td>\n",
       "      <td id=\"T_5075f_row0_col1\" class=\"data row0 col1\" >رئیس‌جمهور   NOUN\n",
       "تاکید        NOUN\n",
       "کرد          VERB\n",
       ":            PUNCT\n",
       "کار          NOUN,EZ\n",
       "این          DET\n",
       "دولت         NOUN\n",
       "فقط          ADV\n",
       "با           ADP\n",
       "نتیجه        NOUN\n",
       "ارزیابی      NOUN\n",
       "می‌شود       VERB\n",
       ".            PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5075f_row1_col0\" class=\"data row1 col0\" >من دیگر تو را دوست ندارم.</td>\n",
       "      <td id=\"T_5075f_row1_col1\" class=\"data row1 col1\" >من      PRON\n",
       "دیگر    ADV\n",
       "تو      PRON\n",
       "را      ADP\n",
       "دوست    NOUN\n",
       "ندارم   VERB\n",
       ".       PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5075f_row2_col0\" class=\"data row2 col0\" >ما یک خانه کامل در بلوک b داریم.</td>\n",
       "      <td id=\"T_5075f_row2_col1\" class=\"data row2 col1\" >ما      PRON\n",
       "یک      NUM\n",
       "خانه    NOUN,EZ\n",
       "کامل    ADJ\n",
       "در      ADP\n",
       "بلوک    NOUN,EZ\n",
       "b       NOUN\n",
       "داریم   VERB\n",
       ".       PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5075f_row3_col0\" class=\"data row3 col0\" >عکس‌های خود را به pr@cuibul. com بفرستید یا در جایی آنلاین قرار دهید و لینک را به همان آدرس ارسال کنید. فراموش نکنید که نام خود را ذکر کنید و شاید یک …</td>\n",
       "      <td id=\"T_5075f_row3_col1\" class=\"data row3 col1\" >عکس‌های     NOUN,EZ\n",
       "خود         PRON\n",
       "را          ADP\n",
       "به          ADP\n",
       "pr@cuibul   NOUN\n",
       ".           PUNCT\n",
       "com         NOUN\n",
       "بفرستید     VERB\n",
       "یا          CCONJ\n",
       "در          ADP\n",
       "جایی        NOUN\n",
       "آنلاین      NOUN\n",
       "قرار        NOUN\n",
       "دهید        VERB\n",
       "و           CCONJ\n",
       "لینک        NOUN\n",
       "را          ADP\n",
       "به          ADP\n",
       "همان        DET\n",
       "آدرس        NOUN\n",
       "ارسال       NOUN\n",
       "کنید        VERB\n",
       ".           PUNCT\n",
       "فراموش      ADJ\n",
       "نکنید       VERB\n",
       "که          SCONJ\n",
       "نام         NOUN,EZ\n",
       "خود         PRON\n",
       "را          ADP\n",
       "ذکر         NOUN\n",
       "کنید        VERB\n",
       "و           CCONJ\n",
       "شاید        ADV\n",
       "یک          NUM\n",
       "…           PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5075f_row4_col0\" class=\"data row4 col0\" >نه. این فقط شما را عالی‌تر می‌کند.</td>\n",
       "      <td id=\"T_5075f_row4_col1\" class=\"data row4 col1\" >نه        ADV\n",
       ".         PUNCT\n",
       "این       PRON\n",
       "فقط       ADV\n",
       "شما       PRON\n",
       "را        ADP\n",
       "عالی‌تر   ADJ\n",
       "می‌کند    VERB\n",
       ".         PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5075f_row5_col0\" class=\"data row5 col0\" >1396 / 12 / 9 12: 05: 56 ق. ظ</td>\n",
       "      <td id=\"T_5075f_row5_col1\" class=\"data row5 col1\" >۱۳۹۶   NUM\n",
       "/      PUNCT\n",
       "۱۲     NUM\n",
       "/      PUNCT\n",
       "۹      NUM\n",
       "۱۲:    NUM,EZ\n",
       "۰۵:    NOUN,EZ\n",
       "۵۶     NUM\n",
       "ق      NOUN\n",
       ".      PUNCT\n",
       "ظ      NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5075f_row6_col0\" class=\"data row6 col0\" >(39 کیلوبایت)</td>\n",
       "      <td id=\"T_5075f_row6_col1\" class=\"data row6 col1\" >(          PUNCT\n",
       "۳۹         NUM\n",
       "کیلوبایت   NOUN\n",
       ")          PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5075f_row7_col0\" class=\"data row7 col0\" >Herscher (Illinois) 815426 **** تلفن</td>\n",
       "      <td id=\"T_5075f_row7_col1\" class=\"data row7 col1\" >Herscher   NOUN\n",
       "(          PUNCT\n",
       "Illinois   NOUN\n",
       ")          PUNCT\n",
       "۸۱۵۴۲۶     NUM\n",
       "****       NOUN\n",
       "تلفن       NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5075f_row8_col0\" class=\"data row8 col0\" >همه‌ی چیزایی که «چندلر» از روی. احساس گناه گرفته رو پس میدم</td>\n",
       "      <td id=\"T_5075f_row8_col1\" class=\"data row8 col1\" >همه‌ی    DET,EZ\n",
       "چیزایی   NOUN\n",
       "که       SCONJ\n",
       "«        PUNCT\n",
       "چندلر    NOUN\n",
       "»        PUNCT\n",
       "از       ADP\n",
       "روی      NOUN\n",
       ".        PUNCT\n",
       "احساس    NOUN,EZ\n",
       "گناه     NOUN\n",
       "گرفته    VERB\n",
       "رو       ADP\n",
       "پس       ADP\n",
       "میدم     VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5075f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5075f_row9_col0\" class=\"data row9 col0\" >11. موتور تون جایزه بزرگ (مسابقه)</td>\n",
       "      <td id=\"T_5075f_row9_col1\" class=\"data row9 col1\" >۱۱.      NOUN\n",
       "موتور    NOUN,EZ\n",
       "تون      NOUN\n",
       "جایزه    NOUN,EZ\n",
       "بزرگ     ADJ\n",
       "(        PUNCT\n",
       "مسابقه   NOUN\n",
       ")        PUNCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x78edba3252e0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/pairs_pos_sample.csv\")  # مسیر را اگر لازم است عوض کن\n",
    "\n",
    "def parse_toktag(s: str):\n",
    "    toks, tags = [], []\n",
    "    if isinstance(s, str):\n",
    "        for chunk in s.split():\n",
    "            if \"/\" in chunk:\n",
    "                tok, tag = chunk.rsplit(\"/\", 1)\n",
    "            else:\n",
    "                tok, tag = chunk, \"\"\n",
    "            toks.append(tok); tags.append(tag)\n",
    "    return toks, tags\n",
    "\n",
    "def pretty_block(s: str):\n",
    "    toks, tags = parse_toktag(s)\n",
    "    if not toks:\n",
    "        return \"\"\n",
    "    w = max(len(t) for t in toks)  # عرض ستون توکن\n",
    "    # هر خط:  token(left padded)   tag\n",
    "    lines = [f\"{t:<{w}}   {g}\" for t, g in zip(toks, tags)]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)  # قطع نکردن متن‌های بلند\n",
    "df[\"pos_pretty\"] = df[\"persian_pos\"].map(pretty_block)\n",
    "\n",
    "# نمایش شکیل (حفظ \\n داخل سلول + فونت مونو)\n",
    "df[[\"persian\", \"pos_pretty\"]].style.set_properties(\n",
    "    subset=[\"pos_pretty\"],\n",
    "    **{\"white-space\": \"pre\", \"font-family\": \"monospace\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0988c364-1d92-499d-a7ed-5ff54b0d3cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
