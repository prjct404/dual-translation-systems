
# Dual Translation Systems (Seq2Seq + Transformer)

An educational/research project that builds a machine translation system with **two approaches**:
1) **LSTM**   
2) **Seq2Seq**


---

## üöÄ Features
Data cleaning & normalization (Fa/En)

Tokenization with SentencePiece (BPE)

Optional POS/NER analysis (Hazm/SpaCy)

Trainable Seq2Seq LSTM (with/without Attention)

Evaluation using sacreBLEU

---

## üì¶ Requirements


- Python ‚â• 3.10
- [PyTorch](https://pytorch.org/get-started/locally/)
- Jupyter Notebook/Lab (optional for EDA)

---

## ‚ñ∂Ô∏è How to Run

```bash
# After clone repo
cd dual-translation-systems
source .venv/bin/activate
run jupyter notebook


```

